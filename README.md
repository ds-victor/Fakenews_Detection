# ğŸ“° Fake News Detection using NLP, LSTM & GloVe

A production-ready Fake News Detection system built using Natural Language Processing (NLP) and a Bi-Directional LSTM model with GloVe word embeddings, deployed as an interactive Streamlit web application.

## ğŸ”— Live App:
ğŸ‘‰ https://fakenewsdetection-vtqt7hkwdt5soeiiesp5qn.streamlit.app/

## ğŸ“Œ Problem Statement

With the rapid spread of misinformation online, identifying fake news articles has become a critical challenge.
This project aims to automatically classify news articles as REAL or FAKE using deep learningâ€“based NLP techniques.

## ğŸš€ Key Features
- NLP preprocessing using NLTK
- Text representation using pre-trained GloVe embeddings
- Bi-Directional LSTM for sequence learning
- Clean separation of:
    - Data preprocessing
    - Model training
    - Inference logic
    - UI layer
- Streamlit Cloud deployment for real-time predictions

## ğŸŒ Live Application
The trained model is deployed using Streamlit Cloud.
### ğŸ”— Try the app here:
ğŸ‘‰ https://fakenewsdetection-vtqt7hkwdt5soeiiesp5qn.streamlit.app/

## App Capabilities
- Paste a news article
- Get instant REAL / FAKE prediction
- View model confidence score

## ğŸ§  Model Architecture
```
Input Text
   â†“
Text Cleaning (NLTK)
   â†“
Tokenization & Padding
   â†“
GloVe Embedding Layer (100-dim)
   â†“
Bi-Directional LSTM
   â†“
Dense Layers
   â†“
Binary Classification (REAL / FAKE)

```
## ğŸ“ Project Structure
```
fakenews_detection/
â”‚
â”œâ”€â”€ app.py              ğŸ‘ˆ Streamlit entry point (ROOT)
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ deployment.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ model.py
â”‚   â””â”€â”€ training.py
â”‚
â”œâ”€â”€ models/
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md

```
## ğŸ“Š Dataset
- Fake.csv â€“ Fake news articles
- True.csv â€“ Real news articles
These are commonly used public datasets for fake news classification tasks.

## ğŸ”¹ GloVe Embeddings (Training Only)

This project uses GloVe Twitter embeddings (100-dim) during training.

ğŸ“¥ Download from:
https://nlp.stanford.edu/projects/glove/

Required file:
```
glove.twitter.27B.100d.txt

```
ğŸ“‚ Place it inside:
```
data/
```
âš ï¸ Note:
The GloVe file (~1GB) is NOT included in this repository due to GitHub size limits.
It is only required for training, not for deployment.

## âš™ï¸ Installation & Setup (Local)
### 1ï¸âƒ£ Create virtual environment
```
python -m venv venv
venv\Scripts\activate   # Windows
```
### 2ï¸âƒ£ Install dependencies
```
pip install -r requirements.txt
```
### 3ï¸âƒ£ Download NLTK resources (one-time)
```
import nltk
nltk.download("punkt")
nltk.download("stopwords")
nltk.download("wordnet")
```
## ğŸ‹ï¸ Model Training

Run training from the project root:
```
python -m src.training
```
This will:
- Preprocess text
- Train the Bi-LSTM model
- Save model & tokenizer in models/

## ğŸŒ Run Streamlit App Locally
From project root:
```
streamlit run app.py
```
Open browser at:
```
http://localhost:8501
```
## ğŸ§ª Example Output

{
  "label": "FAKE",
  "probability_real": 0.14
}

## ğŸ§  Design Decisions & Best Practices
- Single import style (from src...) across the project
- No training in Streamlit app (predict-only deployment)
- Large files (GloVe, NLTK data) excluded via .gitignore
- Model artifacts committed for Streamlit Cloud inference
- Clear separation between experimentation (notebooks) and production code

## ğŸ“Œ Future Enhancements
- Attention mechanism
- Transformer-based models (BERT)
- Model explainability (LIME / SHAP)
- FastAPI backend
- Docker deployment


